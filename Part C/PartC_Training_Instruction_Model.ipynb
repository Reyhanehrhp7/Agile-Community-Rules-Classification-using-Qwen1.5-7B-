{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "727b08bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/012/r/rx/rxh210037/.conda/envs/llmenv/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/012/r/rx/rxh210037/.conda/envs/llmenv/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/012/r/rx/rxh210037/.conda/envs/llmenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "import wandb\n",
    "from huggingface_hub import login, HfApi, create_repo\n",
    "from pathlib import Path\n",
    "# from datasets import Dataset, DatasetDict\n",
    "# from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feaf043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wandb & Huggingface keys\n",
    "hf_token = \"***REMOVED***\"\n",
    "wandb_api_key = \"***REMOVED***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a5ab96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/012/r/rx/rxh210037/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mreyhaneh-rhp7\u001b[0m (\u001b[33mreyhaneh-rhp7-university-of-texas-at-dallas\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to WANDB!\n",
      "Successfully logged in to Hugging Face!\n"
     ]
    }
   ],
   "source": [
    "# Intitialize Weights & Biases\n",
    "if wandb_api_key:\n",
    "    wandb.login(key=wandb_api_key)\n",
    "    print(\"Successfully logged in to WANDB!\")\n",
    "else:\n",
    "    print(\"No wandb key provided. Skipping wandb login.\")\n",
    "\n",
    "if hf_token:\n",
    "    \n",
    "    # Log in to Hugging Face\n",
    "    login(token=hf_token)\n",
    "    print(\"Successfully logged in to Hugging Face!\")\n",
    "else:\n",
    "    print(\"Hugging Face token not found in notebook secrets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0a7a01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rxh210037/LLM/LLM_class/HW4/Part C/wandb/run-20251022_100329-kyjvp1lh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/reyhaneh-rhp7-university-of-texas-at-dallas/PartC_Training_Instruction_Model/runs/kyjvp1lh' target=\"_blank\">PartC_Training_Instruction_Model</a></strong> to <a href='https://wandb.ai/reyhaneh-rhp7-university-of-texas-at-dallas/PartC_Training_Instruction_Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/reyhaneh-rhp7-university-of-texas-at-dallas/PartC_Training_Instruction_Model' target=\"_blank\">https://wandb.ai/reyhaneh-rhp7-university-of-texas-at-dallas/PartC_Training_Instruction_Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/reyhaneh-rhp7-university-of-texas-at-dallas/PartC_Training_Instruction_Model/runs/kyjvp1lh' target=\"_blank\">https://wandb.ai/reyhaneh-rhp7-university-of-texas-at-dallas/PartC_Training_Instruction_Model/runs/kyjvp1lh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/reyhaneh-rhp7-university-of-texas-at-dallas/PartC_Training_Instruction_Model/runs/kyjvp1lh?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe1251b0af0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"PartC_Training_Instruction_Model\", name=\"PartC_Training_Instruction_Model\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bbda10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2029, 9), (10, 8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = Path(\"***/Part C/jigsaw-agile-community-rules\")\n",
    "train_Path = data_folder / \"train.csv\"\n",
    "test_Path = data_folder / \"test.csv\"\n",
    "train = pd.read_csv(train_Path)\n",
    "test = pd.read_csv(test_Path)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "def16952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>body</th>\n",
       "      <th>rule</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>positive_example_1</th>\n",
       "      <th>positive_example_2</th>\n",
       "      <th>negative_example_1</th>\n",
       "      <th>negative_example_2</th>\n",
       "      <th>rule_violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Banks don't want you to know this! Click here ...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>Futurology</td>\n",
       "      <td>If you could tell your younger self something ...</td>\n",
       "      <td>hunt for lady for jack off in neighbourhood ht...</td>\n",
       "      <td>Watch Golden Globe Awards 2017 Live Online in ...</td>\n",
       "      <td>DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...</td>\n",
       "      <td>complies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SD Stream [ ENG Link 1] (http://www.sportsstre...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>soccerstreams</td>\n",
       "      <td>[I wanna kiss you all over! Stunning!](http://...</td>\n",
       "      <td>LOLGA.COM is One of the First Professional Onl...</td>\n",
       "      <td>#Rapper \\n🚨Straight Outta Cross Keys SC 🚨YouTu...</td>\n",
       "      <td>[15 Amazing Hidden Features Of Google Search Y...</td>\n",
       "      <td>complies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lol. Try appealing the ban and say you won't d...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Don't break up with him or call the cops.  If ...</td>\n",
       "      <td>It'll be dismissed: https://en.wikipedia.org/w...</td>\n",
       "      <td>Where is there a site that still works where y...</td>\n",
       "      <td>Because this statement of his is true. It isn'...</td>\n",
       "      <td>violates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>she will come your home open her legs with  an...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>sex</td>\n",
       "      <td>Selling Tyrande codes for 3€ to paypal. PM. \\n...</td>\n",
       "      <td>tight pussy watch for your cock get her at thi...</td>\n",
       "      <td>NSFW(obviously) http://spankbang.com/iy3u/vide...</td>\n",
       "      <td>Good News ::Download WhatsApp 2.16.230 APK for...</td>\n",
       "      <td>violates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>hearthstone</td>\n",
       "      <td>wow!! amazing reminds me of the old days.Well...</td>\n",
       "      <td>seek for lady for sex in around http://p77.pl/...</td>\n",
       "      <td>must be watch movie https://sites.google.com/s...</td>\n",
       "      <td>We're streaming Pokemon Veitnamese Crystal RIG...</td>\n",
       "      <td>violates</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                                               body  \\\n",
       "0       0  Banks don't want you to know this! Click here ...   \n",
       "1       1  SD Stream [ ENG Link 1] (http://www.sportsstre...   \n",
       "2       2  Lol. Try appealing the ban and say you won't d...   \n",
       "3       3  she will come your home open her legs with  an...   \n",
       "4       4  code free tyrande --->>> [Imgur](http://i.imgu...   \n",
       "\n",
       "                                                rule      subreddit  \\\n",
       "0  No Advertising: Spam, referral links, unsolici...     Futurology   \n",
       "1  No Advertising: Spam, referral links, unsolici...  soccerstreams   \n",
       "2  No legal advice: Do not offer or request legal...   pcmasterrace   \n",
       "3  No Advertising: Spam, referral links, unsolici...            sex   \n",
       "4  No Advertising: Spam, referral links, unsolici...    hearthstone   \n",
       "\n",
       "                                  positive_example_1  \\\n",
       "0  If you could tell your younger self something ...   \n",
       "1  [I wanna kiss you all over! Stunning!](http://...   \n",
       "2  Don't break up with him or call the cops.  If ...   \n",
       "3  Selling Tyrande codes for 3€ to paypal. PM. \\n...   \n",
       "4   wow!! amazing reminds me of the old days.Well...   \n",
       "\n",
       "                                  positive_example_2  \\\n",
       "0  hunt for lady for jack off in neighbourhood ht...   \n",
       "1  LOLGA.COM is One of the First Professional Onl...   \n",
       "2  It'll be dismissed: https://en.wikipedia.org/w...   \n",
       "3  tight pussy watch for your cock get her at thi...   \n",
       "4  seek for lady for sex in around http://p77.pl/...   \n",
       "\n",
       "                                  negative_example_1  \\\n",
       "0  Watch Golden Globe Awards 2017 Live Online in ...   \n",
       "1  #Rapper \\n🚨Straight Outta Cross Keys SC 🚨YouTu...   \n",
       "2  Where is there a site that still works where y...   \n",
       "3  NSFW(obviously) http://spankbang.com/iy3u/vide...   \n",
       "4  must be watch movie https://sites.google.com/s...   \n",
       "\n",
       "                                  negative_example_2 rule_violation  \n",
       "0  DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...       complies  \n",
       "1  [15 Amazing Hidden Features Of Google Search Y...       complies  \n",
       "2  Because this statement of his is true. It isn'...       violates  \n",
       "3  Good News ::Download WhatsApp 2.16.230 APK for...       violates  \n",
       "4  We're streaming Pokemon Veitnamese Crystal RIG...       violates  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"rule_violation\"] = train[\"rule_violation\"].map({0: \"complies\", 1: \"violates\"})\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a503c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(val_df, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1ecace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_prepared_path = \"./prepared_data/\"\n",
    "output_dir = \"./outputs_qwen_ruleviolation/\"\n",
    "wandb_project = \"PartC_Training_Instruction_Model\"\n",
    "base_model = \"Qwen/Qwen1.5-7B\"\n",
    "# hf_profile = \"your_hf_username\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aab2aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PROMPT = (\n",
    "    \"You are a rule compliance analyst. \"\n",
    "    \"Your task is to determine whether the following Reddit comment complies with the subreddit rule or violates it. \"\n",
    "    \"Only respond with 'complies' or 'violates'.\\n\\n\"\n",
    ")\n",
    "COMPLETE_PHRASE = \"Decide if this example complies or violates the rule.\"\n",
    "\n",
    "# Build the full user prompt per example\n",
    "def build_prompt(row):\n",
    "    return f\"\"\"\n",
    "{BASE_PROMPT}\n",
    "Subreddit: r/{row['subreddit']}\n",
    "Rule: {row['rule']}\n",
    "\n",
    "Positive Examples:\n",
    "1) {row['positive_example_1']}\n",
    "{COMPLETE_PHRASE}\n",
    "\n",
    "2) {row['positive_example_2']}\n",
    "{COMPLETE_PHRASE}\n",
    "\n",
    "Negative Examples:\n",
    "1) {row['negative_example_1']}\n",
    "{COMPLETE_PHRASE}\n",
    "\n",
    "2) {row['negative_example_2']}\n",
    "{COMPLETE_PHRASE}\n",
    "\n",
    "---\n",
    "Comment: {row['body']}\n",
    "{COMPLETE_PHRASE}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f7fd872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_axolotl_format(df):\n",
    "    return df.apply(\n",
    "        lambda r: {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": build_prompt(r)},\n",
    "                {\"role\": \"assistant\", \"content\": r[\"rule_violation\"]}\n",
    "            ]\n",
    "        },\n",
    "        axis=1\n",
    "    ).tolist()\n",
    "\n",
    "# Build inference format (no assistant replies)\n",
    "def df_to_inference_format(df):\n",
    "    return df.apply(\n",
    "        lambda r: {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": build_prompt(r)}\n",
    "            ]\n",
    "        },\n",
    "        axis=1\n",
    "    ).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1502f4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved 1623 records to prepared_data/train.jsonl\n",
      " Saved 203 records to prepared_data/validation.jsonl\n",
      " Saved 203 records to prepared_data/test.jsonl\n",
      " Saved 10 records to prepared_data/test_inference.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "output_dir = Path(\"prepared_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Convert train and validation sets\n",
    "train_data = df_to_axolotl_format(train_df)\n",
    "val_data = df_to_axolotl_format(val_df)\n",
    "test_data= df_to_axolotl_format(test_df)\n",
    "\n",
    "test_inference_data = df_to_inference_format(test)\n",
    "\n",
    "# Save to JSONL\n",
    "def save_jsonl(data, filename):\n",
    "    path = output_dir / filename\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "    print(f\" Saved {len(data)} records to {path}\")\n",
    "\n",
    "save_jsonl(train_data, \"train.jsonl\")\n",
    "save_jsonl(val_data, \"validation.jsonl\")\n",
    "save_jsonl(test_data, \"test.jsonl\")\n",
    "save_jsonl(test_inference_data, \"test_inference.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67505c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_prepared_path = \"./prepared_data/\"\n",
    "output_dir = \"./outputs_qwen_ruleviolation/\"\n",
    "wandb_project = \"PartC_Training_Instruction_Model\"\n",
    "base_model = \"Qwen/Qwen1.5-7B\"\n",
    "# hf_profile = \"your_hf_username\"a/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6ec88a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " YAML config saved as config_partc.yaml\n"
     ]
    }
   ],
   "source": [
    "yaml_template = f\"\"\"\n",
    "seed: 42\n",
    "torch_seed: 42\n",
    "\n",
    "datasets:\n",
    "  - path: {dataset_prepared_path}\n",
    "    type: chat_template\n",
    "    field_messages: messages\n",
    "    chat_template: tokenizer_default\n",
    "    train_on_split: train\n",
    "\n",
    "test_datasets:\n",
    "  - path: {dataset_prepared_path}\n",
    "    type: chat_template\n",
    "    field_messages: messages\n",
    "    chat_template: tokenizer_default\n",
    "    split: test\n",
    "    \n",
    "train_on_inputs: false\n",
    "\n",
    "base_model: {base_model}\n",
    "load_in_4bit: true\n",
    "adapter: qlora\n",
    "lora_r: 64\n",
    "lora_alpha: 128\n",
    "lora_dropout: 0.05\n",
    "lora_target_linear: true\n",
    "\n",
    "load_best_model_at_end: true\n",
    "eval_strategy: epoch\n",
    "save_strategy: epoch\n",
    "metric_for_best_model: eval_loss\n",
    "greater_is_better: false\n",
    "\n",
    "micro_batch_size: 2\n",
    "gradient_accumulation_steps: 8\n",
    "gradient_checkpointing: true\n",
    "fp16: true\n",
    "\n",
    "learning_rate: 2e-4\n",
    "lr_scheduler: cosine\n",
    "num_epochs: 3\n",
    "optimizer: paged_adamw_8bit\n",
    "warmup_ratio: 0.1\n",
    "\n",
    "output_dir: {output_dir}\n",
    "report_to: wandb\n",
    "wandb_project: {wandb_project}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"config_partc.yaml\", \"w\") as f:\n",
    "    f.write(yaml_template)\n",
    "\n",
    "print(\" YAML config saved as config_partc.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5f1a03d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     #@@ #@@      @@# @@#\n",
      "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
      "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
      "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
      "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
      "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
      "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
      "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
      "    @@@@  @@@@@@@@@@@@@@@@\n",
      "\n",
      "[2025-10-22 13:54:32,280] [INFO] [axolotl.cli.config] config:\n",
      "{\n",
      "  \"activation_offloading\": false,\n",
      "  \"adapter\": \"qlora\",\n",
      "  \"axolotl_config_path\": \"config_partc.yaml\",\n",
      "  \"base_model\": \"Qwen/Qwen1.5-7B\",\n",
      "  \"base_model_config\": \"Qwen/Qwen1.5-7B\",\n",
      "  \"batch_size\": 16,\n",
      "  \"bf16\": false,\n",
      "  \"capabilities\": {\n",
      "    \"bf16\": true,\n",
      "    \"compute_capability\": \"sm_86\",\n",
      "    \"fp8\": false,\n",
      "    \"n_gpu\": 1,\n",
      "    \"n_node\": 1\n",
      "  },\n",
      "  \"context_parallel_size\": 1,\n",
      "  \"dataloader_num_workers\": 1,\n",
      "  \"dataloader_pin_memory\": true,\n",
      "  \"dataloader_prefetch_factor\": 256,\n",
      "  \"dataset_num_proc\": 24,\n",
      "  \"datasets\": [\n",
      "    {\n",
      "      \"chat_template\": \"tokenizer_default\",\n",
      "      \"field_messages\": \"messages\",\n",
      "      \"message_property_mappings\": {\n",
      "        \"content\": \"content\",\n",
      "        \"role\": \"role\"\n",
      "      },\n",
      "      \"path\": \"./prepared_data//train.jsonl\",\n",
      "      \"trust_remote_code\": false,\n",
      "      \"type\": \"chat_template\"\n",
      "    }\n",
      "  ],\n",
      "  \"ddp\": false,\n",
      "  \"device\": \"cuda:0\",\n",
      "  \"device_map\": \"auto\",\n",
      "  \"dion_rank_fraction\": 1.0,\n",
      "  \"dion_rank_multiple_of\": 1,\n",
      "  \"env_capabilities\": {\n",
      "    \"torch_version\": \"2.8.0\"\n",
      "  },\n",
      "  \"eval_batch_size\": 2,\n",
      "  \"eval_causal_lm_metrics\": [\n",
      "    \"sacrebleu\",\n",
      "    \"comet\",\n",
      "    \"ter\",\n",
      "    \"chrf\"\n",
      "  ],\n",
      "  \"eval_max_new_tokens\": 128,\n",
      "  \"eval_strategy\": \"epoch\",\n",
      "  \"eval_table_size\": 0,\n",
      "  \"experimental_skip_move_to_device\": true,\n",
      "  \"fp16\": true,\n",
      "  \"gradient_accumulation_steps\": 8,\n",
      "  \"gradient_checkpointing\": true,\n",
      "  \"gradient_checkpointing_kwargs\": {\n",
      "    \"use_reentrant\": true\n",
      "  },\n",
      "  \"greater_is_better\": false,\n",
      "  \"include_tkps\": true,\n",
      "  \"is_preprocess\": true,\n",
      "  \"learning_rate\": 0.0002,\n",
      "  \"lisa_layers_attribute\": \"model.layers\",\n",
      "  \"load_best_model_at_end\": true,\n",
      "  \"load_in_4bit\": true,\n",
      "  \"load_in_8bit\": false,\n",
      "  \"local_rank\": 0,\n",
      "  \"lora_alpha\": 128,\n",
      "  \"lora_dropout\": 0.05,\n",
      "  \"lora_r\": 64,\n",
      "  \"lora_target_linear\": true,\n",
      "  \"loraplus_lr_embedding\": 1e-06,\n",
      "  \"lr_scheduler\": \"cosine\",\n",
      "  \"mean_resizing_embeddings\": false,\n",
      "  \"metric_for_best_model\": \"eval_loss\",\n",
      "  \"micro_batch_size\": 2,\n",
      "  \"model_config_type\": \"qwen2\",\n",
      "  \"num_epochs\": 3.0,\n",
      "  \"optimizer\": \"paged_adamw_8bit\",\n",
      "  \"output_dir\": \"prepared_data\",\n",
      "  \"pretrain_multipack_attn\": true,\n",
      "  \"profiler_steps_start\": 0,\n",
      "  \"qlora_sharded_model_loading\": false,\n",
      "  \"ray_num_workers\": 1,\n",
      "  \"resources_per_worker\": {\n",
      "    \"GPU\": 1\n",
      "  },\n",
      "  \"sample_packing_bin_size\": 200,\n",
      "  \"sample_packing_group_size\": 100000,\n",
      "  \"save_only_model\": false,\n",
      "  \"save_safetensors\": true,\n",
      "  \"save_strategy\": \"epoch\",\n",
      "  \"seed\": 42,\n",
      "  \"sequence_len\": 512,\n",
      "  \"shuffle_before_merging_datasets\": false,\n",
      "  \"shuffle_merged_datasets\": true,\n",
      "  \"skip_prepare_dataset\": false,\n",
      "  \"streaming_multipack_buffer_size\": 10000,\n",
      "  \"strict\": false,\n",
      "  \"tensor_parallel_size\": 1,\n",
      "  \"test_datasets\": [\n",
      "    {\n",
      "      \"chat_template\": \"tokenizer_default\",\n",
      "      \"field_messages\": \"messages\",\n",
      "      \"message_property_mappings\": {\n",
      "        \"content\": \"content\",\n",
      "        \"role\": \"role\"\n",
      "      },\n",
      "      \"path\": \"./prepared_data/\",\n",
      "      \"split\": \"validation\",\n",
      "      \"trust_remote_code\": false,\n",
      "      \"type\": \"chat_template\"\n",
      "    },\n",
      "    {\n",
      "      \"chat_template\": \"tokenizer_default\",\n",
      "      \"field_messages\": \"messages\",\n",
      "      \"message_property_mappings\": {\n",
      "        \"content\": \"content\",\n",
      "        \"role\": \"role\"\n",
      "      },\n",
      "      \"path\": \"./prepared_data/\",\n",
      "      \"split\": \"test\",\n",
      "      \"trust_remote_code\": false,\n",
      "      \"type\": \"chat_template\"\n",
      "    }\n",
      "  ],\n",
      "  \"tiled_mlp_use_original_mlp\": true,\n",
      "  \"tokenizer_config\": \"Qwen/Qwen1.5-7B\",\n",
      "  \"tokenizer_save_jinja_files\": true,\n",
      "  \"torch_dtype\": \"torch.float16\",\n",
      "  \"train_on_inputs\": false,\n",
      "  \"trl\": {\n",
      "    \"log_completions\": false,\n",
      "    \"mask_truncated_completions\": false,\n",
      "    \"ref_model_mixup_alpha\": 0.9,\n",
      "    \"ref_model_sync_steps\": 64,\n",
      "    \"scale_rewards\": true,\n",
      "    \"sync_ref_model\": false,\n",
      "    \"use_vllm\": false,\n",
      "    \"vllm_server_host\": \"0.0.0.0\",\n",
      "    \"vllm_server_port\": 8000\n",
      "  },\n",
      "  \"use_ray\": false,\n",
      "  \"use_wandb\": true,\n",
      "  \"val_set_size\": 0.0,\n",
      "  \"vllm\": {\n",
      "    \"device\": \"auto\",\n",
      "    \"dtype\": \"auto\",\n",
      "    \"gpu_memory_utilization\": 0.9,\n",
      "    \"host\": \"0.0.0.0\",\n",
      "    \"port\": 8000\n",
      "  },\n",
      "  \"wandb_project\": \"PartC_Training_Instruction_Model\",\n",
      "  \"warmup_ratio\": 0.1,\n",
      "  \"weight_decay\": 0.0,\n",
      "  \"world_size\": 1\n",
      "}\n",
      "[2025-10-22 13:54:32,330] [WARNING] [axolotl.cli.preprocess] preprocess CLI called without dataset_prepared_path set, using default path: last_run_prepared\n",
      "[2025-10-22 13:54:32,696] [INFO] [axolotl.utils.data.shared] Unable to find prepared dataset in last_run_prepared/e4e710d4d267a1a44373c4eb136652e3\n",
      "[2025-10-22 13:54:32,696] [INFO] [axolotl.utils.data.sft] Loading raw datasets...\n",
      "[2025-10-22 13:54:32,893] [INFO] [axolotl.utils.data.wrappers] Loading dataset: ./prepared_data//train.jsonl with base_type: chat_template and prompt_style: None\n",
      "[2025-10-22 13:54:32,895] [INFO] [axolotl.prompt_strategies.chat_template] Using chat template:\n",
      "---\n",
      "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\n",
      "You are a helpful assistant<|im_end|>\n",
      "' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "---\n",
      "[2025-10-22 13:54:32,899] [WARNING] [axolotl.prompt_strategies.chat_template] EOS token '<|endoftext|>' not found in chat_template. Please check if your template/EOS token is correct.\n",
      "Tokenizing Prompts (num_proc=24): 100%|█| 2029/2029 [00:02<00:00, 795.18 example\n",
      "[2025-10-22 13:54:35,528] [INFO] [axolotl.utils.data.utils] min_input_len: 253\n",
      "[2025-10-22 13:54:35,528] [INFO] [axolotl.utils.data.utils] max_input_len: 704\n",
      "Dropping Long Sequences (>512) (num_proc=24): 100%|█| 2029/2029 [00:00<00:00, 53\n",
      "[2025-10-22 13:54:35,949] [WARNING] [axolotl.utils.data.utils] Dropped 94 samples from dataset\n",
      "Saving the dataset (7/7 shards): 100%|█| 1935/1935 [00:00<00:00, 10578.22 exampl\n",
      "[2025-10-22 13:54:36,151] [INFO] [axolotl.utils.data.shared] Unable to find prepared dataset in last_run_prepared/f0cd88fc2109b72b681145d2d825b7f0\n",
      "[2025-10-22 13:54:36,152] [INFO] [axolotl.utils.data.sft] Loading raw datasets...\n",
      "[2025-10-22 13:54:36,176] [INFO] [axolotl.utils.data.wrappers] Loading dataset: ./prepared_data/ with base_type: chat_template and prompt_style: None\n",
      "[2025-10-22 13:54:36,176] [INFO] [axolotl.prompt_strategies.chat_template] Using chat template:\n",
      "---\n",
      "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\n",
      "You are a helpful assistant<|im_end|>\n",
      "' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "---\n",
      "[2025-10-22 13:54:36,180] [WARNING] [axolotl.prompt_strategies.chat_template] EOS token '<|endoftext|>' not found in chat_template. Please check if your template/EOS token is correct.\n",
      "Tokenizing Prompts (num_proc=24): 100%|█| 203/203 [00:02<00:00, 88.45 examples/s\n",
      "[2025-10-22 13:54:38,567] [INFO] [axolotl.utils.data.wrappers] Loading dataset: ./prepared_data/ with base_type: chat_template and prompt_style: None\n",
      "[2025-10-22 13:54:38,568] [INFO] [axolotl.prompt_strategies.chat_template] Using chat template:\n",
      "---\n",
      "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\n",
      "You are a helpful assistant<|im_end|>\n",
      "' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "---\n",
      "[2025-10-22 13:54:38,572] [WARNING] [axolotl.prompt_strategies.chat_template] EOS token '<|endoftext|>' not found in chat_template. Please check if your template/EOS token is correct.\n",
      "Tokenizing Prompts (num_proc=24):  92%|▉| 197/213 [00:02<00:00, 129.83 examples/[2025-10-22 13:54:40,757] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 13:54:40,758] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 13:54:40,801] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 13:54:40,802] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 13:54:40,803] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 13:54:40,804] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 13:54:40,805] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 13:54:40,805] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 13:54:40,806] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 13:54:40,807] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "Tokenizing Prompts (num_proc=24): 100%|█| 213/213 [00:02<00:00, 91.68 examples/s\n",
      "[2025-10-22 13:54:40,974] [INFO] [axolotl.utils.data.shared] Merging datasets...\n",
      "[2025-10-22 13:54:40,984] [INFO] [axolotl.utils.data.utils] min_input_len: 269\n",
      "[2025-10-22 13:54:40,984] [INFO] [axolotl.utils.data.utils] max_input_len: 589\n",
      "Dropping Long Sequences (>512) (num_proc=24): 100%|█| 416/416 [00:00<00:00, 1108\n",
      "[2025-10-22 13:54:41,412] [WARNING] [axolotl.utils.data.utils] Dropped 20 samples from dataset\n",
      "Saving the dataset (1/1 shards): 100%|█| 396/396 [00:00<00:00, 40916.01 examples\n",
      "[2025-10-22 13:54:41,425] [INFO] [axolotl.common.datasets] check_dataset_labels...\n",
      "[2025-10-22 13:54:41,429] [INFO] [axolotl.utils.tokenization] <|im_start|>(-100, 151644) system(-100, 8948) \n",
      "(-100, 198) You(-100, 2610)  are(-100, 525)  a(-100, 264)  helpful(-100, 10950)  assistant(-100, 17847) <|im_end|>(-100, 151645) \n",
      "(-100, 198) <|im_start|>(-100, 151644) user(-100, 872) \n",
      "(-100, 198) You(-100, 2610)  are(-100, 525)  a(-100, 264)  rule(-100, 5912)  compliance(-100, 8733)  analyst(-100, 18237) .(-100, 13)  Your(-100, 4615)  task(-100, 3383)  is(-100, 374)  to(-100, 311)  determine(-100, 8253)  whether(-100, 3425)  the(-100, 279)  following(-100, 2701)  Reddit(-100, 26630)  comment(-100, 3980)  compl(-100, 4581) ies(-100, 550)  with(-100, 448)  the(-100, 279)  subreddit(-100, 62092)  rule(-100, 5912)  or(-100, 476)  violates(-100, 50313)  it(-100, 432) .(-100, 13)  Only(-100, 8278)  respond(-100, 5889)  with(-100, 448)  '(-100, 364) com(-100, 874) plies(-100, 7202) '(-100, 6)  or(-100, 476)  '(-100, 364) viol(-100, 55151) ates(-100, 973) '(-100, 6) .\n",
      "\n",
      "\n",
      "(-100, 4192) Sub(-100, 3136) reddit(-100, 36933) :(-100, 25)  r(-100, 435) /The(-100, 47748) _D(-100, 1557) onald(-100, 79694) \n",
      "(-100, 198) Rule(-100, 11337) :(-100, 25)  No(-100, 2308)  legal(-100, 5777)  advice(-100, 9462) :(-100, 25)  Do(-100, 3155)  not(-100, 537)  offer(-100, 3010)  or(-100, 476)  request(-100, 1681)  legal(-100, 5777)  advice(-100, 9462) .\n",
      "\n",
      "(-100, 382) Positive(-100, 35490)  Examples(-100, 25311) :\n",
      "(-100, 510) 1(-100, 16) )(-100, 8)  Don(-100, 4320) 't(-100, 944)  get(-100, 633)  out(-100, 700)  of(-100, 315)  the(-100, 279)  house(-100, 3753) ,(-100, 11)  he(-100, 566)  did(-100, 1521)  nothing(-100, 4302)  wrong(-100, 4969) .(-100, 13)  Kick(-100, 26678)  the(-100, 279)  lying(-100, 20446)  bitch(-100, 39430)  wife(-100, 7403)  out(-100, 700)  of(-100, 315)  the(-100, 279)  house(-100, 3753)  or(-100, 476)  he(-100, 566)  risks(-100, 15276)  losing(-100, 13188)  it(-100, 432)  in(-100, 304)  the(-100, 279)  divorce(-100, 24532) .(-100, 13)  I(-100, 358)  don(-100, 1513) 't(-100, 944)  know(-100, 1414)  a(-100, 264)  lot(-100, 2696)  about(-100, 911)  this(-100, 419)  but(-100, 714)  I(-100, 358)  do(-100, 653)  know(-100, 1414)  that(-100, 429)  it(-100, 432) 's(-100, 594)  mentioned(-100, 9733)  when(-100, 979)  ending(-100, 13391)  a(-100, 264)  marriage(-100, 10866)  it(-100, 432) 's(-100, 594)  bad(-100, 3873)  to(-100, 311)  leave(-100, 5274)  the(-100, 279)  home(-100, 2114)  as(-100, 438)  somehow(-100, 16925)  it(-100, 432)  can(-100, 646)  legally(-100, 25202)  jeopard(-100, 52032) ize(-100, 551)  who(-100, 879)  gets(-100, 5221)  to(-100, 311)  stay(-100, 4717)  in(-100, 304)  the(-100, 279)  divorce(-100, 24532) .(-100, 13)  Not(-100, 2806)  that(-100, 429)  he(-100, 566)  would(-100, 1035)  want(-100, 1366)  to(-100, 311)  live(-100, 3887)  there(-100, 1052)  after(-100, 1283)  anyway(-100, 13657)  but(-100, 714)  he(-100, 566)  can(-100, 646)  at(-100, 518)  least(-100, 3245)  sell(-100, 4559)  the(-100, 279)  house(-100, 3753) ,(-100, 11)  maybe(-100, 7196)  to(-100, 311)  a(-100, 264)  nice(-100, 6419)  swinging(-100, 53960)  couple(-100, 5625) .(-100, 13)   \n",
      "(-100, 2303) Dec(-100, 4900) ide(-100, 577)  if(-100, 421)  this(-100, 419)  example(-100, 3110)  compl(-100, 4581) ies(-100, 550)  or(-100, 476)  violates(-100, 50313)  the(-100, 279)  rule(-100, 5912) .\n",
      "\n",
      "(-100, 382) 2(-100, 17) )(-100, 8)  Yeah(-100, 21607)  this(-100, 419)  isn(-100, 4436) 't(-100, 944)  anything(-100, 4113)  to(-100, 311)  worry(-100, 10955)  about(-100, 911) .\n",
      "\n",
      "(-100, 382) If(-100, 2679)  your(-100, 697)  under(-100, 1212)  (-100, 220) 1(-100, 16) 8(-100, 23)  and(-100, 323)  prostit(-100, 11197) uting(-100, 10607)  your(-100, 697)  probably(-100, 4658)  a(-100, 264)  victim(-100, 11734)  of(-100, 315)  sex(-100, 1839)  trafficking(-100, 33463)  and(-100, 323)  this(-100, 419)  just(-100, 1101)  removes(-100, 28160)  the(-100, 279)  punishment(-100, 24093)  for(-100, 369)  being(-100, 1660)  forced(-100, 9575)  into(-100, 1119)  prostitution(-100, 49750) .(-100, 13)  I(-100, 358)  doubt(-100, 10492)  it(-100, 432)  was(-100, 572)  ever(-100, 3512)  enforced(-100, 44321)  anyway(-100, 13657) .(-100, 13)  \"(-100, 330) Oh(-100, 11908)  hey(-100, 34209)  your(-100, 697)  safe(-100, 6092)  from(-100, 504)  sex(-100, 1839)  trafficking(-100, 33463)  now(-100, 1431) ,(-100, 11)  now(-100, 1431)  your(-100, 697)  under(-100, 1212)  arrest(-100, 8004) \"\n",
      "(-100, 698) Dec(-100, 4900) ide(-100, 577)  if(-100, 421)  this(-100, 419)  example(-100, 3110)  compl(-100, 4581) ies(-100, 550)  or(-100, 476)  violates(-100, 50313)  the(-100, 279)  rule(-100, 5912) .\n",
      "\n",
      "(-100, 382) Negative(-100, 38489)  Examples(-100, 25311) :\n",
      "(-100, 510) 1(-100, 16) )(-100, 8)  In(-100, 758)  the(-100, 279)  UK(-100, 6424)  at(-100, 518)  least(-100, 3245) ,(-100, 11)  the(-100, 279)  officer(-100, 9452)  chooses(-100, 39911)  when(-100, 979)  to(-100, 311)  stop(-100, 2936)  and(-100, 323)  start(-100, 1191)  the(-100, 279)  recording(-100, 14633) ,(-100, 11)  so(-100, 773)  they(-100, 807)  should(-100, 1265)  be(-100, 387)  able(-100, 2952)  to(-100, 311)  avoid(-100, 5648)  this(-100, 419) .\n",
      "(-100, 624) Dec(-100, 4900) ide(-100, 577)  if(-100, 421)  this(-100, 419)  example(-100, 3110)  compl(-100, 4581) ies(-100, 550)  or(-100, 476)  violates(-100, 50313)  the(-100, 279)  rule(-100, 5912) .\n",
      "\n",
      "(-100, 382) 2(-100, 17) )(-100, 8)  Well(-100, 8325)  it(-100, 432)  is(-100, 374)  but(-100, 714)  we(-100, 582)  stole(-100, 39506)  it(-100, 432)  from(-100, 504)  them(-100, 1105)  fair(-100, 6624)  and(-100, 323)  square(-100, 9334) .\n",
      "(-100, 624) Dec(-100, 4900) ide(-100, 577)  if(-100, 421)  this(-100, 419)  example(-100, 3110)  compl(-100, 4581) ies(-100, 550)  or(-100, 476)  violates(-100, 50313)  the(-100, 279)  rule(-100, 5912) .\n",
      "\n",
      "(-100, 382) ---\n",
      "(-100, 10952) Comment(-100, 10677) :(-100, 25)  Muslim(-100, 10240)  citizens(-100, 10283)  that(-100, 429)  leave(-100, 5274)  the(-100, 279)  country(-100, 3146)  are(-100, 525)  not(-100, 537)  allowed(-100, 5420)  back(-100, 1182)  in(-100, 304) .(-100, 13)  (-100, 220)  This(-100, 1096)  is(-100, 374)  a(-100, 264)  clear(-100, 2797)  violation(-100, 19940)  of(-100, 315)  equal(-100, 6144)  protection(-100, 9135)  laws(-100, 6872) .\n",
      "(-100, 624) Dec(-100, 4900) ide(-100, 577)  if(-100, 421)  this(-100, 419)  example(-100, 3110)  compl(-100, 4581) ies(-100, 550)  or(-100, 476)  violates(-100, 50313)  the(-100, 279)  rule(-100, 5912) .(-100, 13) <|im_end|>(-100, 151645) \n",
      "(-100, 198) <|im_start|>(-100, 151644) assistant(-100, 77091) \n",
      "(-100, 198) viol(55151, 55151) ates(973, 973) <|im_end|>(-100, 151645) \n",
      "(-100, 198)\n",
      "[2025-10-22 13:54:41,429] [INFO] [axolotl.utils.tokenization] \n",
      "\n",
      "\n",
      "\n",
      "[2025-10-22 13:54:41,429] [INFO] [axolotl.utils.tokenization] Total input len: 383\n",
      "[2025-10-22 13:54:41,429] [INFO] [axolotl.utils.tokenization] Count of labels: 2\n",
      "[2025-10-22 13:54:41,429] [INFO] [axolotl.common.datasets] printing prompters...\n",
      "[2025-10-22 13:54:41,429] [INFO] [axolotl.common.datasets] Pre-tokenized or custom dataset types are unsupported for logging\n",
      "[2025-10-22 13:54:41,512] [INFO] [axolotl.cli.preprocess] Success! Preprocessed data path: `dataset_prepared_path: last_run_prepared`\n"
     ]
    }
   ],
   "source": [
    "!axolotl preprocess config_partc.yaml --debug\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "50848160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2025-10-22 14:13:15,028] [INFO] [axolotl.cli.config] config:\n",
      "{\n",
      "  \"activation_offloading\": false,\n",
      "  \"adapter\": \"qlora\",\n",
      "  \"axolotl_config_path\": \"config_partc.yaml\",\n",
      "  \"base_model\": \"Qwen/Qwen1.5-7B\",\n",
      "  \"base_model_config\": \"Qwen/Qwen1.5-7B\",\n",
      "  \"batch_size\": 16,\n",
      "  \"bf16\": false,\n",
      "  \"capabilities\": {\n",
      "    \"bf16\": true,\n",
      "    \"compute_capability\": \"sm_86\",\n",
      "    \"fp8\": false,\n",
      "    \"n_gpu\": 1,\n",
      "    \"n_node\": 1\n",
      "  },\n",
      "  \"context_parallel_size\": 1,\n",
      "  \"dataloader_num_workers\": 1,\n",
      "  \"dataloader_pin_memory\": true,\n",
      "  \"dataloader_prefetch_factor\": 256,\n",
      "  \"dataset_num_proc\": 24,\n",
      "  \"datasets\": [\n",
      "    {\n",
      "      \"chat_template\": \"tokenizer_default\",\n",
      "      \"field_messages\": \"messages\",\n",
      "      \"message_property_mappings\": {\n",
      "        \"content\": \"content\",\n",
      "        \"role\": \"role\"\n",
      "      },\n",
      "      \"path\": \"./prepared_data/\",\n",
      "      \"trust_remote_code\": false,\n",
      "      \"type\": \"chat_template\"\n",
      "    }\n",
      "  ],\n",
      "  \"ddp\": false,\n",
      "  \"device\": \"cuda:0\",\n",
      "  \"dion_rank_fraction\": 1.0,\n",
      "  \"dion_rank_multiple_of\": 1,\n",
      "  \"env_capabilities\": {\n",
      "    \"torch_version\": \"2.8.0\"\n",
      "  },\n",
      "  \"eval_batch_size\": 2,\n",
      "  \"eval_causal_lm_metrics\": [\n",
      "    \"sacrebleu\",\n",
      "    \"comet\",\n",
      "    \"ter\",\n",
      "    \"chrf\"\n",
      "  ],\n",
      "  \"eval_max_new_tokens\": 128,\n",
      "  \"eval_strategy\": \"epoch\",\n",
      "  \"eval_table_size\": 0,\n",
      "  \"experimental_skip_move_to_device\": true,\n",
      "  \"fp16\": true,\n",
      "  \"gradient_accumulation_steps\": 8,\n",
      "  \"gradient_checkpointing\": true,\n",
      "  \"gradient_checkpointing_kwargs\": {\n",
      "    \"use_reentrant\": true\n",
      "  },\n",
      "  \"greater_is_better\": false,\n",
      "  \"include_tkps\": true,\n",
      "  \"learning_rate\": 0.0002,\n",
      "  \"lisa_layers_attribute\": \"model.layers\",\n",
      "  \"load_best_model_at_end\": true,\n",
      "  \"load_in_4bit\": true,\n",
      "  \"load_in_8bit\": false,\n",
      "  \"local_rank\": 0,\n",
      "  \"lora_alpha\": 128,\n",
      "  \"lora_dropout\": 0.05,\n",
      "  \"lora_r\": 64,\n",
      "  \"lora_target_linear\": true,\n",
      "  \"loraplus_lr_embedding\": 1e-06,\n",
      "  \"lr_scheduler\": \"cosine\",\n",
      "  \"mean_resizing_embeddings\": false,\n",
      "  \"metric_for_best_model\": \"eval_loss\",\n",
      "  \"micro_batch_size\": 2,\n",
      "  \"model_config_type\": \"qwen2\",\n",
      "  \"num_epochs\": 3.0,\n",
      "  \"optimizer\": \"paged_adamw_8bit\",\n",
      "  \"output_dir\": \"prepared_data\",\n",
      "  \"pretrain_multipack_attn\": true,\n",
      "  \"profiler_steps_start\": 0,\n",
      "  \"qlora_sharded_model_loading\": false,\n",
      "  \"ray_num_workers\": 1,\n",
      "  \"resources_per_worker\": {\n",
      "    \"GPU\": 1\n",
      "  },\n",
      "  \"sample_packing_bin_size\": 200,\n",
      "  \"sample_packing_group_size\": 100000,\n",
      "  \"save_only_model\": false,\n",
      "  \"save_safetensors\": true,\n",
      "  \"save_strategy\": \"epoch\",\n",
      "  \"seed\": 42,\n",
      "  \"sequence_len\": 512,\n",
      "  \"shuffle_before_merging_datasets\": false,\n",
      "  \"shuffle_merged_datasets\": true,\n",
      "  \"skip_prepare_dataset\": false,\n",
      "  \"streaming_multipack_buffer_size\": 10000,\n",
      "  \"strict\": false,\n",
      "  \"tensor_parallel_size\": 1,\n",
      "  \"test_datasets\": [\n",
      "    {\n",
      "      \"chat_template\": \"tokenizer_default\",\n",
      "      \"field_messages\": \"messages\",\n",
      "      \"message_property_mappings\": {\n",
      "        \"content\": \"content\",\n",
      "        \"role\": \"role\"\n",
      "      },\n",
      "      \"path\": \"./prepared_data/\",\n",
      "      \"split\": \"test\",\n",
      "      \"trust_remote_code\": false,\n",
      "      \"type\": \"chat_template\"\n",
      "    }\n",
      "  ],\n",
      "  \"tiled_mlp_use_original_mlp\": true,\n",
      "  \"tokenizer_config\": \"Qwen/Qwen1.5-7B\",\n",
      "  \"tokenizer_save_jinja_files\": true,\n",
      "  \"torch_dtype\": \"torch.float16\",\n",
      "  \"train_on_inputs\": false,\n",
      "  \"trl\": {\n",
      "    \"log_completions\": false,\n",
      "    \"mask_truncated_completions\": false,\n",
      "    \"ref_model_mixup_alpha\": 0.9,\n",
      "    \"ref_model_sync_steps\": 64,\n",
      "    \"scale_rewards\": true,\n",
      "    \"sync_ref_model\": false,\n",
      "    \"use_vllm\": false,\n",
      "    \"vllm_server_host\": \"0.0.0.0\",\n",
      "    \"vllm_server_port\": 8000\n",
      "  },\n",
      "  \"use_ray\": false,\n",
      "  \"use_wandb\": true,\n",
      "  \"val_set_size\": 0.0,\n",
      "  \"vllm\": {\n",
      "    \"device\": \"auto\",\n",
      "    \"dtype\": \"auto\",\n",
      "    \"gpu_memory_utilization\": 0.9,\n",
      "    \"host\": \"0.0.0.0\",\n",
      "    \"port\": 8000\n",
      "  },\n",
      "  \"wandb_project\": \"PartC_Training_Instruction_Model\",\n",
      "  \"warmup_ratio\": 0.1,\n",
      "  \"weight_decay\": 0.0,\n",
      "  \"world_size\": 1\n",
      "}\n",
      "[2025-10-22 14:13:15,616] [INFO] [axolotl.utils.data.shared] Unable to find prepared dataset in last_run_prepared/70220e28e1bf32717b08ce05f64575dc\n",
      "[2025-10-22 14:13:15,616] [INFO] [axolotl.utils.data.sft] Loading raw datasets...\n",
      "[2025-10-22 14:13:15,616] [WARNING] [axolotl.utils.data.sft] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset using `axolotl preprocess path/to/config.yml`.\n",
      "Generating train split: 2029 examples [00:00, 203317.08 examples/s]\n",
      "Generating validation split: 203 examples [00:00, 131436.20 examples/s]\n",
      "Generating test split: 213 examples [00:00, 110145.08 examples/s]\n",
      "[2025-10-22 14:13:15,670] [INFO] [axolotl.utils.data.wrappers] Loading dataset: ./prepared_data/ with base_type: chat_template and prompt_style: None\n",
      "[2025-10-22 14:13:15,672] [INFO] [axolotl.prompt_strategies.chat_template] Using chat template:\n",
      "---\n",
      "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\n",
      "You are a helpful assistant<|im_end|>\n",
      "' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "---\n",
      "[2025-10-22 14:13:15,676] [WARNING] [axolotl.prompt_strategies.chat_template] EOS token '<|endoftext|>' not found in chat_template. Please check if your template/EOS token is correct.\n",
      "Tokenizing Prompts (num_proc=24): 100%|█| 2029/2029 [00:02<00:00, 791.88 example\n",
      "[2025-10-22 14:13:18,322] [INFO] [axolotl.utils.data.utils] min_input_len: 253\n",
      "[2025-10-22 14:13:18,323] [INFO] [axolotl.utils.data.utils] max_input_len: 704\n",
      "Dropping Long Sequences (>512) (num_proc=24): 100%|█| 2029/2029 [00:00<00:00, 57\n",
      "[2025-10-22 14:13:18,718] [WARNING] [axolotl.utils.data.utils] Dropped 94 samples from dataset\n",
      "Saving the dataset (7/7 shards): 100%|█| 1935/1935 [00:00<00:00, 10524.55 exampl\n",
      "[2025-10-22 14:13:18,921] [INFO] [axolotl.utils.data.shared] Unable to find prepared dataset in last_run_prepared/519842ef57b25f927ebb7fac084226b1\n",
      "[2025-10-22 14:13:18,921] [INFO] [axolotl.utils.data.sft] Loading raw datasets...\n",
      "[2025-10-22 14:13:18,921] [WARNING] [axolotl.utils.data.sft] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset using `axolotl preprocess path/to/config.yml`.\n",
      "[2025-10-22 14:13:18,937] [INFO] [axolotl.utils.data.wrappers] Loading dataset: ./prepared_data/ with base_type: chat_template and prompt_style: None\n",
      "[2025-10-22 14:13:18,937] [INFO] [axolotl.prompt_strategies.chat_template] Using chat template:\n",
      "---\n",
      "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\n",
      "You are a helpful assistant<|im_end|>\n",
      "' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "---\n",
      "[2025-10-22 14:13:18,942] [WARNING] [axolotl.prompt_strategies.chat_template] EOS token '<|endoftext|>' not found in chat_template. Please check if your template/EOS token is correct.\n",
      "Tokenizing Prompts (num_proc=24):  92%|▉| 197/213 [00:02<00:00, 129.97 examples/[2025-10-22 14:13:21,123] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 14:13:21,124] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 14:13:21,162] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 14:13:21,163] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 14:13:21,164] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 14:13:21,165] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 14:13:21,166] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 14:13:21,166] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 14:13:21,167] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "[2025-10-22 14:13:21,168] [WARNING] [axolotl.prompt_strategies.chat_template] Last turn is not trainable, skipping having to find the turn indices. This may cause incorrect last EOT/EOS token to be unmasked.This is likely a dataset design issue. Please ensure last turn is trainable.\n",
      "Tokenizing Prompts (num_proc=24): 100%|█| 213/213 [00:02<00:00, 92.61 examples/s\n",
      "[2025-10-22 14:13:21,327] [INFO] [axolotl.utils.data.utils] min_input_len: 269\n",
      "[2025-10-22 14:13:21,327] [INFO] [axolotl.utils.data.utils] max_input_len: 589\n",
      "Dropping Long Sequences (>512) (num_proc=24): 100%|█| 213/213 [00:00<00:00, 635.\n",
      "[2025-10-22 14:13:21,701] [WARNING] [axolotl.utils.data.utils] Dropped 12 samples from dataset\n",
      "Saving the dataset (1/1 shards): 100%|█| 201/201 [00:00<00:00, 1581.80 examples/\n",
      "[2025-10-22 14:13:21,852] [INFO] [axolotl.utils.data.sft] Maximum number of steps set at 363\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:04<00:00,  1.23s/it]\n",
      "[2025-10-22 14:13:27,665] [INFO] [axolotl.loaders.model] converting PEFT model w/ prepare_model_for_kbit_training\n",
      "[2025-10-22 14:13:27,668] [INFO] [axolotl.loaders.model] Converting modules to torch.float16\n",
      "[2025-10-22 14:13:27,671] [INFO] [axolotl.loaders.adapter] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\n",
      "trainable params: 159,907,840 || all params: 7,881,232,384 || trainable%: 2.0290\n",
      "[2025-10-22 14:13:29,218] [WARNING] [py.warnings] /home/012/r/rx/rxh210037/.conda/envs/llmenv/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "\n",
      "[2025-10-22 14:13:29,219] [WARNING] [py.warnings] /home/012/r/rx/rxh210037/.conda/envs/llmenv/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "\n",
      "[2025-10-22 14:13:30,653] [INFO] [axolotl.evaluate] Starting train set evaluation...\n",
      "[2025-10-22 14:13:30,653] [INFO] [axolotl.core.trainers.base] Running evaluation step...\n",
      "100%|█████████████████████████████████████████| 968/968 [03:57<00:00,  4.47it/s]wandb: Currently logged in as: reyhaneh-rhp7 (reyhaneh-rhp7-university-of-texas-at-dallas) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: ⢿ Waiting for wandb.init()...\n",
      "wandb: ⣻ Waiting for wandb.init()...\n",
      "wandb: Tracking run with wandb version 0.22.0\n",
      "wandb: Run data is saved locally in /home/rxh210037/LLM/LLM_class/HW4/Part C/wandb/run-20251022_141729-8vqr6apr\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run dutiful-plant-46\n",
      "wandb: ⭐️ View project at https://wandb.ai/reyhaneh-rhp7-university-of-texas-at-dallas/PartC_Training_Instruction_Model\n",
      "wandb: 🚀 View run at https://wandb.ai/reyhaneh-rhp7-university-of-texas-at-dallas/PartC_Training_Instruction_Model/runs/8vqr6apr\n",
      "wandb: Detected [huggingface_hub.inference, openai] in use.\n",
      "wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/\n",
      "100%|█████████████████████████████████████████| 968/968 [03:58<00:00,  4.06it/s]\n",
      "[2025-10-22 14:17:29,842] [INFO] [axolotl.evaluate] Train set evaluation completed!\n",
      "[2025-10-22 14:17:29,842] [INFO] [axolotl.evaluate] Train Metrics:\n",
      "[2025-10-22 14:17:29,842] [INFO] [axolotl.evaluate] train_loss: 1.8255614042282104\n",
      "[2025-10-22 14:17:29,842] [INFO] [axolotl.evaluate] train_model_preparation_time: 0.0038\n",
      "[2025-10-22 14:17:29,842] [INFO] [axolotl.evaluate] train_runtime: 238.3381\n",
      "[2025-10-22 14:17:29,842] [INFO] [axolotl.evaluate] train_samples_per_second: 8.119\n",
      "[2025-10-22 14:17:29,842] [INFO] [axolotl.evaluate] train_steps_per_second: 4.061\n",
      "[2025-10-22 14:17:29,842] [INFO] [axolotl.evaluate] memory/max_active (GiB): 7.83\n",
      "[2025-10-22 14:17:29,842] [INFO] [axolotl.evaluate] memory/max_allocated (GiB): 7.83\n",
      "[2025-10-22 14:17:29,842] [INFO] [axolotl.evaluate] memory/device_reserved (GiB): 11.7\n",
      "[2025-10-22 14:17:29,842] [INFO] [axolotl.evaluate] Starting eval set evaluation...\n",
      "[2025-10-22 14:17:29,842] [INFO] [axolotl.core.trainers.base] Running evaluation step...\n",
      "100%|█████████████████████████████████████████| 101/101 [00:24<00:00,  4.04it/s]\n",
      "[2025-10-22 14:17:55,098] [INFO] [axolotl.evaluate] Eval set evaluation completed!\n",
      "[2025-10-22 14:17:55,098] [INFO] [axolotl.evaluate] Eval Metrics:\n",
      "[2025-10-22 14:17:55,098] [INFO] [axolotl.evaluate] eval_loss: 1.7525094747543335\n",
      "[2025-10-22 14:17:55,098] [INFO] [axolotl.evaluate] eval_model_preparation_time: 0.0038\n",
      "[2025-10-22 14:17:55,098] [INFO] [axolotl.evaluate] eval_runtime: 25.2459\n",
      "[2025-10-22 14:17:55,098] [INFO] [axolotl.evaluate] eval_samples_per_second: 7.962\n",
      "[2025-10-22 14:17:55,098] [INFO] [axolotl.evaluate] eval_steps_per_second: 4.001\n",
      "[2025-10-22 14:17:55,098] [INFO] [axolotl.evaluate] memory/max_active (GiB): 7.83\n",
      "[2025-10-22 14:17:55,098] [INFO] [axolotl.evaluate] memory/max_allocated (GiB): 7.83\n",
      "[2025-10-22 14:17:55,098] [INFO] [axolotl.evaluate] memory/device_reserved (GiB): 9.19\n",
      "[2025-10-22 14:17:55,098] [INFO] [axolotl.evaluate] Evaluation results saved to prepared_data/eval_summary.csv\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch -m axolotl.cli.evaluate config_partc.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c5ffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loss: 1.8255614042282104\n",
    "#eval_loss: 1.7828916311264038"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "27a8fc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">PartC_Training_Instruction_Model</strong> at: <a href='https://wandb.ai/reyhaneh-rhp7-university-of-texas-at-dallas/PartC_Training_Instruction_Model/runs/kyjvp1lh' target=\"_blank\">https://wandb.ai/reyhaneh-rhp7-university-of-texas-at-dallas/PartC_Training_Instruction_Model/runs/kyjvp1lh</a><br> View project at: <a href='https://wandb.ai/reyhaneh-rhp7-university-of-texas-at-dallas/PartC_Training_Instruction_Model' target=\"_blank\">https://wandb.ai/reyhaneh-rhp7-university-of-texas-at-dallas/PartC_Training_Instruction_Model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251022_100329-kyjvp1lh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
